# Tasks
* classification-hf: Huggingface model based Classfication task
* pretrain-hf: Pre-training code for Huggingface models
    * roberta: masked lm training

# Sources
* roberta
    * https://towardsdatascience.com/transformers-retraining-roberta-base-using-the-roberta-mlm-procedure-7422160d5764
    * https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorForLanguageModeling