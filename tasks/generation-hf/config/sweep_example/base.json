{
    "pretrained_model": "hyunwoongko/kobart",
    "encoder_max_length" : 128,
    "decoder_max_length" : 64,
    "per_device_batch_size": 32,
    "epochs": 30,
    "gradient_accumulation_steps": 1,
    "dropout": 0.1,
    "label_smoothing_factor": 0.1,
    "learning_rate": 1e-5,
    "warmup_proportion": 0.1,
    "adam_epsilon": 1e-8,
    "warmup_steps": 0,
    "max_grad_norm": 1,
    "logging_steps": 80,
    "save_strategy": "steps",
    "save_steps": 80,
    "save_total_limit": 1,
    "evaluation_strategy": "steps",
    "summary_step": 80,
    "evaluate_during_training": true,
    "metric_for_best_model": "eval_loss",
    "seed": 100,
    "fp16": false,
    "bf16": false
  }